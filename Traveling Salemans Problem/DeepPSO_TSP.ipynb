{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T14:06:38.425883Z",
     "iopub.status.busy": "2025-01-04T14:06:38.425542Z",
     "iopub.status.idle": "2025-01-04T14:06:52.074890Z",
     "shell.execute_reply": "2025-01-04T14:06:52.073805Z",
     "shell.execute_reply.started": "2025-01-04T14:06:38.425851Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install the correct version of PyTorch for Colab\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Install PyTorch Geometric dependencies\n",
    "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.4.1+cu121.html\n",
    "\n",
    "# Install PyTorch Geometric\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-04T14:06:52.076833Z",
     "iopub.status.busy": "2025-01-04T14:06:52.076538Z",
     "iopub.status.idle": "2025-01-04T14:24:22.854627Z",
     "shell.execute_reply": "2025-01-04T14:24:22.853334Z",
     "shell.execute_reply.started": "2025-01-04T14:06:52.076810Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.distributions import MultivariateNormal\n",
    "import torch.optim as optim\n",
    "\n",
    "# Data Handling Functions\n",
    "def read_tsp_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    start_idx = lines.index('NODE_COORD_SECTION\\n') + 1\n",
    "    end_idx = lines.index('EOF\\n')\n",
    "    coordinates = []\n",
    "    for line in lines[start_idx:end_idx]:\n",
    "        _, x, y = line.strip().split()\n",
    "        coordinates.append((float(x), float(y)))\n",
    "\n",
    "    coordinates = np.array(coordinates)\n",
    "    return coordinates\n",
    "\n",
    "def calculate_distance_matrix(coordinates):\n",
    "    \"\"\"\n",
    "    Tính ma trận khoảng cách Euclide 2D giữa các điểm trong `coordinates`.\n",
    "\n",
    "    Args:\n",
    "        coordinates (np.ndarray): Mảng numpy có kích thước (n, 2), trong đó n là số điểm,\n",
    "                                   mỗi điểm có 2 tọa độ (x, y).\n",
    "    Returns:\n",
    "        torch.Tensor: Ma trận khoảng cách (n x n) dạng tensor.\n",
    "    \"\"\"\n",
    "    n = coordinates.shape[0]\n",
    "    distance_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            dx = coordinates[i, 0] - coordinates[j, 0]\n",
    "            dy = coordinates[i, 1] - coordinates[j, 1]\n",
    "            distance_matrix[i, j] = np.sqrt(dx**2 + dy**2)\n",
    "    return torch.tensor(distance_matrix, dtype=torch.float32)\n",
    "\n",
    "class TSPDataset(Dataset):\n",
    "    def __init__(self, dataset_dir, num_cities):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.num_cities = num_cities\n",
    "        self.files = [os.path.join(dataset_dir, f) for f in os.listdir(dataset_dir) if f.endswith('.tsp')]\n",
    "        self.valid_files = []\n",
    "        self._filter_files()\n",
    "\n",
    "    def _filter_files(self):\n",
    "        for file in self.files:\n",
    "            coordinates = read_tsp_file(file)\n",
    "            if coordinates.shape[0] == self.num_cities:\n",
    "                self.valid_files.append(file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = self.valid_files[idx]\n",
    "        coordinates = read_tsp_file(file)\n",
    "        distance_matrix = calculate_distance_matrix(coordinates)\n",
    "        return {\n",
    "            'coordinates': torch.tensor(coordinates, dtype=torch.float32),\n",
    "            'distance_matrix': distance_matrix\n",
    "       }\n",
    "\n",
    "def create_dataloader(dataset_dir, num_cities, batch_size, shuffle=True, num_workers=4):\n",
    "    dataset = TSPDataset(dataset_dir, num_cities)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "    return dataloader\n",
    "\n",
    "# Model Definition\n",
    "class CityGNN(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=32, output_dim=3, num_cities=20):\n",
    "        super(CityGNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.city_gnn = GCNConv(input_dim, hidden_dim)\n",
    "        self.edge_gnn = GCNConv(1, hidden_dim)\n",
    "        self.fc_combine = nn.Linear(3 * hidden_dim, hidden_dim)\n",
    "        self.fc_output_mean = nn.Linear(hidden_dim, output_dim)\n",
    "        self.fc_output_cov = nn.Linear(hidden_dim, output_dim * output_dim)\n",
    "        \n",
    "        # Precompute edge_index for a fully connected graph\n",
    "        edge_indices = torch.cartesian_prod(torch.arange(num_cities), torch.arange(num_cities)).t().contiguous()\n",
    "        self.register_buffer('edge_index', edge_indices)\n",
    "        \n",
    "        # Initialize solution_param here to ensure it's on the correct device\n",
    "        self.solution_param = nn.Parameter(torch.randn(num_cities, hidden_dim))\n",
    "        \n",
    "        # Khởi tạo trọng số với hàm init_weights đã sửa\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, GCNConv):\n",
    "            nn.init.xavier_uniform_(m.lin.weight) \n",
    "            if m.lin.bias is not None:\n",
    "                nn.init.zeros_(m.lin.bias)\n",
    "\n",
    "    def forward(self, city_positions, distance_matrix, solutions):\n",
    "        B, n, _ = city_positions.size()\n",
    "        device = city_positions.device\n",
    "\n",
    "        # Use precomputed edge_index\n",
    "        edge_index = self.edge_index.to(device)\n",
    "\n",
    "        # GCN on city positions\n",
    "        city_features = F.relu(self.city_gnn(city_positions, edge_index))  # B x n x hidden_dim\n",
    "\n",
    "        # GCN on edge distances\n",
    "        dist_flat = distance_matrix.view(B, -1, 1)  # B x (n*n) x 1\n",
    "        edge_features = F.relu(self.edge_gnn(dist_flat, edge_index))  # B x (n*n) x hidden_dim\n",
    "        edge_features = edge_features.view(B, n, n, self.hidden_dim).mean(dim=2)  # B x n x hidden_dim\n",
    "\n",
    "        # Solution features\n",
    "        solution_features = torch.matmul(solutions, self.solution_param)  # B x K x hidden_dim (K=n)\n",
    "\n",
    "        # Combine features\n",
    "        combined_features = torch.cat([city_features, edge_features, solution_features], dim=-1)  # B x n x (3*hidden_dim)\n",
    "        combined_features = F.relu(self.fc_combine(combined_features))  # B x n x hidden_dim\n",
    "\n",
    "        # Output mean and covariance\n",
    "        means = self.fc_output_mean(combined_features)  # B x n x 3\n",
    "        covariances = self.fc_output_cov(combined_features).view(B, n, 3, 3)  # B x n x 3 x 3\n",
    "        \n",
    "        # Sử dụng softplus để đảm bảo giá trị dương\n",
    "        covariances = F.softplus(covariances)\n",
    "        # Giới hạn covariance matrices để tránh quá lớn\n",
    "        covariances = covariances @ covariances.transpose(-1, -2)  # Ensure positive semi-definite\n",
    "        covariances += torch.eye(3, device=device).unsqueeze(0).unsqueeze(0) * 1e-2  # Add noise for stability\n",
    "        \n",
    "        return means, covariances\n",
    "\n",
    "\n",
    "# Action Sampler\n",
    "class ActionSampler:\n",
    "    def __init__(self, gnn_model):\n",
    "        self.gnn_model = gnn_model\n",
    "\n",
    "    def sample_action(self, city_positions, distance_matrix, solutions):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            city_positions (Tensor): B x n x 2.\n",
    "            distance_matrix (Tensor): B x n x n.\n",
    "            solutions (Tensor): B x n x n.\n",
    "\n",
    "        Returns:\n",
    "            actions (Tensor): B x n x 3.\n",
    "            log_probs (Tensor): B x n.\n",
    "        \"\"\"\n",
    "        means, covariances = self.gnn_model(city_positions, distance_matrix, solutions)\n",
    "        dist = MultivariateNormal(means, covariances)\n",
    "        sampled_actions = dist.rsample()\n",
    "        sampled_actions = torch.sigmoid(sampled_actions)\n",
    "        log_probs = dist.log_prob(sampled_actions)\n",
    "\n",
    "        return sampled_actions, log_probs\n",
    "\n",
    "# Fitness Calculation\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def compute_fitness_loss(positions, distance_matrix):\n",
    "    B, K, n = positions.size()\n",
    "    \n",
    "    decoded_tours = torch.argsort(positions, dim=2, descending=True)  # B x K x n\n",
    "    decoded_tours_extended = torch.cat([decoded_tours, decoded_tours[:, :, :1]], dim=2)  # B x K x (n+1)\n",
    "\n",
    "    city_a = decoded_tours_extended[:, :, :-1]  # B x K x n\n",
    "    city_b = decoded_tours_extended[:, :, 1:]   # B x K x n\n",
    "\n",
    "    linear_indices = city_a * n + city_b  # B x K x n\n",
    "\n",
    "    distance_flat = distance_matrix.view(B, -1)  # B x (n*n)\n",
    "    distances = torch.gather(distance_flat, 1, linear_indices.view(B, K * n)).view(B, K, n)\n",
    "\n",
    "    total_distance = distances.sum(dim=2)  # B x K\n",
    "    return total_distance, decoded_tours\n",
    "\n",
    "def decode(positions):\n",
    "    decoded_tours = torch.argsort(positions, dim=1, descending=True)  # B x n\n",
    "\n",
    "    return decoded_tours\n",
    "\n",
    "def train_model(model, train_loader, num_cities, pso_iterations=25, epochs=50, batch_size=16, lr=1e-4, gamma=0.99, device='cuda', save_path=\"psognn.pth\"):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adamax(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_pso_loss = 0.0\n",
    "        total_policy_loss = 0.0\n",
    "        batch_count = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch_count += 1\n",
    "            city_positions = batch['coordinates'].to(device)  # B x n x 2\n",
    "            distance_matrices = batch['distance_matrix'].to(device)  # B x n x n\n",
    "\n",
    "            # Initialize positions và velocities\n",
    "            B, n = city_positions.size(0), num_cities\n",
    "            K = n  # Number of solutions per problem\n",
    "            positions = torch.rand((B, K, n), dtype=torch.float32, device=device)  # B x K x n\n",
    "            velocities = torch.zeros_like(positions, device=device)  # B x K x n\n",
    "\n",
    "            # Compute initial p_best\n",
    "            p_best_fitness, _ = compute_fitness_loss(positions, distance_matrices)  # B x K\n",
    "            p_best_positions = positions.clone().detach()  # B x K x n\n",
    "\n",
    "            # Compute initial g_best\n",
    "            g_best_fitness, g_best_indices = p_best_fitness.min(dim=1)  # B\n",
    "            g_best_position = positions[torch.arange(B, device=device), g_best_indices]  # B x n\n",
    "\n",
    "            # Initialize lists to store log probabilities và rewards\n",
    "            log_probs_list = []\n",
    "            rewards_list = []\n",
    "\n",
    "            for iteration in range(pso_iterations):\n",
    "                # Tạo ActionSampler mới trong mỗi iteration\n",
    "                sampler = ActionSampler(model)\n",
    "\n",
    "                # Sample actions tại mỗi iteration\n",
    "                actions, log_probs = sampler.sample_action(city_positions, distance_matrices, positions)  # B x K x 3, B x K\n",
    "                # print(f\"Step: {iteration} action {actions}, log_probs {log_probs}\")\n",
    "\n",
    "                # Tách các tham số hành động từ actions\n",
    "                w = actions[:, :, 0].unsqueeze(-1)  # B x K x 1\n",
    "                c1 = actions[:, :, 1].unsqueeze(-1)  # B x K x 1\n",
    "                c2 = actions[:, :, 2].unsqueeze(-1)  # B x K x 1\n",
    "\n",
    "                # Tính toán điều kiện hội tụ\n",
    "                convergence_condition = (1 + w - c1 - c2) ** 2  # Điều kiện hội tụ\n",
    "                penalty_threshold = 4 * w  # Ngưỡng phạt\n",
    "\n",
    "                # Cấp phần thưởng/phạt dựa trên điều kiện hội tụ\n",
    "                convergence_rewards = torch.where(\n",
    "                    convergence_condition < penalty_threshold,\n",
    "                    torch.tensor(10, device=positions.device),  # Phần thưởng\n",
    "                    torch.tensor(-5, device=positions.device)  # Phạt\n",
    "                ).squeeze(-1)\n",
    "\n",
    "                # Cập nhật velocities và positions\n",
    "                velocities = (\n",
    "                    w * velocities +\n",
    "                    c1 * (p_best_positions - positions) +\n",
    "                    c2 * (g_best_position.unsqueeze(1) - positions)  # B x K x n\n",
    "                ) \n",
    "                # + 0.001 * torch.randn_like(velocities)\n",
    "                positions = positions + velocities \n",
    "                positions = torch.sigmoid(positions)\n",
    "                positions = positions.detach()\n",
    "                fitness, decoded_tours = compute_fitness_loss(positions, distance_matrices)  # B x K, B x K x n\n",
    "                log_probs_list.append(log_probs)  # List of B x K\n",
    "\n",
    "                # Kết hợp reward từ hội tụ và loss\n",
    "                rewards_list.append(-fitness)  # List of B x K\n",
    "\n",
    "                # Cập nhật p_best\n",
    "                better_mask = fitness < p_best_fitness  # B x K\n",
    "                p_best_positions = torch.where(better_mask.unsqueeze(-1), positions, p_best_positions)  # B x K x n\n",
    "                p_best_fitness = torch.min(fitness, p_best_fitness)  # B x K\n",
    "\n",
    "                # Cập nhật g_best\n",
    "                g_best_fitness_new, g_best_indices_new = fitness.min(dim=1)  # B\n",
    "                update_mask = g_best_fitness_new < g_best_fitness  # B\n",
    "                g_best_fitness = torch.min(g_best_fitness, g_best_fitness_new)  # B\n",
    "                g_best_position_new = positions[torch.arange(B, device=device), g_best_indices_new]  # B x n\n",
    "\n",
    "                g_best_position = torch.where(\n",
    "                    update_mask.unsqueeze(-1),\n",
    "                    g_best_position_new,\n",
    "                    g_best_position\n",
    "                )  # B x n\n",
    "\n",
    "            # Stack log_probs và rewards\n",
    "            log_probs_tensor = torch.cat(log_probs_list, dim=1)  # B x (K * pso_iterations)\n",
    "            rewards_tensor = torch.cat(rewards_list, dim=1)      # B x (K * pso_iterations)\n",
    "            rewards_tensor = (rewards_tensor - rewards_tensor.mean()) / (rewards_tensor.std() + 1e-8)\n",
    "            # rewards_tensor = torch.clamp(rewards_tensor, min=-400.0, max=400.0)\n",
    "            # Compute discounted rewards\n",
    "            discounted_rewards = rewards_tensor.clone()\n",
    "            for t in range(rewards_tensor.size(1) - 2, -1, -1):\n",
    "                discounted_rewards[:, t] += gamma * discounted_rewards[:, t + 1]\n",
    "\n",
    "            policy_loss = -(log_probs_tensor * discounted_rewards).mean()\n",
    "            pso_loss = g_best_fitness.mean()  # Scalar\n",
    "            # total_loss = policy_loss + pso_loss\n",
    "            optimizer.zero_grad()\n",
    "            policy_loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate losses\n",
    "            total_pso_loss += pso_loss.item()\n",
    "            total_policy_loss += policy_loss.item()\n",
    "\n",
    "        # Compute average losses cho epoch\n",
    "        avg_pso_loss = total_pso_loss / batch_count\n",
    "        avg_policy_loss = total_policy_loss / batch_count\n",
    "\n",
    "        scheduler.step(avg_pso_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Average PSO Loss: {avg_pso_loss:.4f}, Average Policy Loss: {avg_policy_loss:.4f}\\n\")\n",
    "\n",
    "    # Training Runner\n",
    "def run_training(num_cities=20, train_data_path=\"train\", batch_size=16, lr=1e-4, epochs=50, pso_iterations=25, save_path=\"psognn.pth\", device=\"cuda\"):\n",
    "    print(\"Loading training data...\")\n",
    "    train_loader = create_dataloader(train_data_path, num_cities, batch_size, shuffle=True)\n",
    "\n",
    "    print(\"Initializing model...\")\n",
    "    model = CityGNN(input_dim=2, hidden_dim=128, output_dim=3, num_cities=num_cities)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        num_cities=num_cities,\n",
    "        pso_iterations=pso_iterations,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        lr=lr,\n",
    "        device=device,\n",
    "        save_path=save_path\n",
    "    )\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    run_training(\n",
    "        num_cities=20,\n",
    "        train_data_path=\"/kaggle/input/20-citi/train\",\n",
    "        batch_size=32,\n",
    "        lr=1e-4,\n",
    "        epochs=30,\n",
    "        pso_iterations=50,\n",
    "        save_path=\"/kaggle/working/psognn.pth\",\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T14:24:22.857347Z",
     "iopub.status.busy": "2025-01-04T14:24:22.856419Z",
     "iopub.status.idle": "2025-01-04T14:26:02.157530Z",
     "shell.execute_reply": "2025-01-04T14:26:02.137228Z",
     "shell.execute_reply.started": "2025-01-04T14:24:22.857288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def test_model(model, test_loader, num_cities, pso_iterations=5, device=\"cuda\", seed=625):\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_best_fitness = []  # Lưu giá trị tốt nhất của tất cả bài toán\n",
    "    results = []  # Lưu kết quả của từng bài toán\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_id, batch in enumerate(test_loader):\n",
    "            city_positions = batch['coordinates'].to(device)  # B x n x 2\n",
    "            distance_matrices = batch['distance_matrix'].to(device)  # B x n x n\n",
    "\n",
    "            B, n = city_positions.size(0), num_cities\n",
    "            K = n  # Số lời giải cho mỗi bài toán\n",
    "\n",
    "            best_fitness_per_problem = []\n",
    "\n",
    "            for _ in range(pso_iterations):\n",
    "                # Initialize positions and velocities\n",
    "                positions = torch.rand((B, K, n), dtype=torch.float32, device=device)  # B x K x n\n",
    "                velocities = torch.zeros_like(positions, device=device)  # B x K x n\n",
    "\n",
    "                # Compute initial g_best\n",
    "                fitness, _ = compute_fitness_loss(positions, distance_matrices)  # B x K\n",
    "                g_best_fitness, g_best_indices = fitness.min(dim=1)  # B\n",
    "                g_best_position = positions[torch.arange(B, device=device), g_best_indices]  # B x n\n",
    "\n",
    "                for iteration in range(pso_iterations):\n",
    "                    # Tạo ActionSampler mới trong mỗi iteration\n",
    "                    sampler = ActionSampler(model)\n",
    "\n",
    "                    # Sample actions tại mỗi iteration\n",
    "                    actions, _ = sampler.sample_action(city_positions, distance_matrices, positions)  # B x K x 3\n",
    "\n",
    "                    # Tách các tham số hành động từ actions\n",
    "                    w = actions[:, :, 0].unsqueeze(-1)  # B x K x 1\n",
    "                    c1 = actions[:, :, 1].unsqueeze(-1)  # B x K x 1\n",
    "                    c2 = actions[:, :, 2].unsqueeze(-1)  # B x K x 1\n",
    "\n",
    "                    # Cập nhật velocities và positions\n",
    "                    velocities = (\n",
    "                        w * velocities +\n",
    "                        c1 * (positions - g_best_position.unsqueeze(1)) +\n",
    "                        c2 * (g_best_position.unsqueeze(1) - positions)\n",
    "                    )\n",
    "                    positions = positions + velocities\n",
    "                    positions = torch.sigmoid(positions)\n",
    "\n",
    "                    # Tính fitness\n",
    "                    fitness, _ = compute_fitness_loss(positions, distance_matrices)  # B x K\n",
    "\n",
    "                    # Cập nhật g_best\n",
    "                    g_best_fitness_new, g_best_indices_new = fitness.min(dim=1)  # B\n",
    "                    update_mask = g_best_fitness_new < g_best_fitness  # B\n",
    "                    g_best_fitness = torch.min(g_best_fitness, g_best_fitness_new)  # B\n",
    "                    g_best_position_new = positions[torch.arange(B, device=device), g_best_indices_new]  # B x n\n",
    "\n",
    "                    g_best_position = torch.where(\n",
    "                        update_mask.unsqueeze(-1),\n",
    "                        g_best_position_new,\n",
    "                        g_best_position\n",
    "                    )  # B x n\n",
    "\n",
    "                # Lưu lại fitness tốt nhất cho mỗi lần chạy\n",
    "                best_fitness_per_problem.append(g_best_fitness.cpu().numpy())\n",
    "\n",
    "            # Tính toán các giá trị cần thiết cho từng bài toán\n",
    "            best_fitness_per_problem = np.array(best_fitness_per_problem)  # (pso_iterations x B)\n",
    "            best_fitness = best_fitness_per_problem.min(axis=0)  # Giá trị tốt nhất từng bài toán\n",
    "            worst_fitness = best_fitness_per_problem.max(axis=0)  # Giá trị tệ nhất từng bài toán\n",
    "            avg_fitness = best_fitness_per_problem.mean(axis=0)  # Giá trị trung bình từng bài toán\n",
    "\n",
    "            # Lưu kết quả\n",
    "            for i in range(B):\n",
    "                results.append({\n",
    "                    \"problem_id\": batch_id * B + i,\n",
    "                    \"best_fitness\": best_fitness[i],\n",
    "                    \"worst_fitness\": worst_fitness[i],\n",
    "                    \"avg_fitness\": avg_fitness[i]\n",
    "                })\n",
    "\n",
    "            all_best_fitness.extend(best_fitness)\n",
    "\n",
    "    # Tính giá trị trung bình tốt nhất của tất cả các bài toán\n",
    "    overall_best_avg = np.mean(all_best_fitness)\n",
    "\n",
    "    # In kết quả\n",
    "    for result in results:\n",
    "        print(f\"Problem {result['problem_id']} - Best: {result['best_fitness']:.4f}, \"\n",
    "              f\"Worst: {result['worst_fitness']:.4f}, Avg: {result['avg_fitness']:.4f}\")\n",
    "\n",
    "    print(f\"\\nOverall Average Best Fitness: {overall_best_avg:.4f}\")\n",
    "    return results, overall_best_avg\n",
    "def run_test(model, test_loader, num_cities, seed=625):\n",
    "    print(\"Running test...\")\n",
    "    results, overall_best_avg = test_model(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        num_cities=num_cities,\n",
    "        pso_iterations=25,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        seed=seed\n",
    "    )\n",
    "    print(\"Test completed.\")\n",
    "    return results, overall_best_avg\n",
    "if __name__ == \"__main__\":\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    # Giả định rằng TSPDataset và mô hình đã được định nghĩa từ trước\n",
    "    test_dataset = \"/kaggle/input/20-test/test\"\n",
    "    test_loader = create_dataloader(test_dataset, num_cities = 20, batch_size = 32, shuffle=True)\n",
    "\n",
    "    # Tạo một mô hình giả định đã được huấn luyện\n",
    "    model = CityGNN(input_dim=2, hidden_dim=128, output_dim=3, num_cities=20)\n",
    "\n",
    "    # Chạy test\n",
    "    results, overall_best_avg = run_test(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        num_cities=20,\n",
    "        seed=625\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T14:26:02.159196Z",
     "iopub.status.busy": "2025-01-04T14:26:02.158811Z",
     "iopub.status.idle": "2025-01-04T14:26:03.198632Z",
     "shell.execute_reply": "2025-01-04T14:26:03.197362Z",
     "shell.execute_reply.started": "2025-01-04T14:26:02.159163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def test_model(model, test_loader, num_cities, pso_iterations=5, device=\"cuda\", seed=None):\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_best_fitness = []  # Lưu giá trị tốt nhất của tất cả bài toán\n",
    "    results = []  # Lưu kết quả của từng bài toán\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_id, batch in enumerate(test_loader):\n",
    "            city_positions = batch['coordinates'].to(device)  # B x n x 2\n",
    "            distance_matrices = batch['distance_matrix'].to(device)  # B x n x n\n",
    "\n",
    "            B, n = city_positions.size(0), num_cities\n",
    "            K = n  # Số lời giải cho mỗi bài toán\n",
    "\n",
    "            best_fitness_per_problem = []\n",
    "\n",
    "            for _ in range(pso_iterations):\n",
    "                # Initialize positions and velocities\n",
    "                positions = torch.rand((B, K, n), dtype=torch.float32, device=device)  # B x K x n\n",
    "                velocities = torch.zeros_like(positions, device=device)  # B x K x n\n",
    "\n",
    "                # Compute initial g_best\n",
    "                fitness, _ = compute_fitness_loss(positions, distance_matrices)  # B x K\n",
    "                g_best_fitness, g_best_indices = fitness.min(dim=1)  # B\n",
    "                g_best_position = positions[torch.arange(B, device=device), g_best_indices]  # B x n\n",
    "\n",
    "                for iteration in range(pso_iterations):\n",
    "                    # Tạo ActionSampler mới trong mỗi iteration\n",
    "                    sampler = ActionSampler(model)\n",
    "\n",
    "                    # Sample actions tại mỗi iteration\n",
    "                    actions, _ = sampler.sample_action(city_positions, distance_matrices, positions)  # B x K x 3\n",
    "\n",
    "                    # Tách các tham số hành động từ actions\n",
    "                    w = actions[:, :, 0].unsqueeze(-1)  # B x K x 1\n",
    "                    c1 = actions[:, :, 1].unsqueeze(-1)  # B x K x 1\n",
    "                    c2 = actions[:, :, 2].unsqueeze(-1)  # B x K x 1\n",
    "\n",
    "                    # Cập nhật velocities và positions\n",
    "                    velocities = (\n",
    "                        w * velocities +\n",
    "                        c1 * (positions - g_best_position.unsqueeze(1)) +\n",
    "                        c2 * (g_best_position.unsqueeze(1) - positions)\n",
    "                    )\n",
    "                    positions = positions + velocities\n",
    "                    positions = torch.sigmoid(positions)\n",
    "\n",
    "                    # Tính fitness\n",
    "                    fitness, _ = compute_fitness_loss(positions, distance_matrices)  # B x K\n",
    "\n",
    "                    # Cập nhật g_best\n",
    "                    g_best_fitness_new, g_best_indices_new = fitness.min(dim=1)  # B\n",
    "                    update_mask = g_best_fitness_new < g_best_fitness  # B\n",
    "                    g_best_fitness = torch.min(g_best_fitness, g_best_fitness_new)  # B\n",
    "                    g_best_position_new = positions[torch.arange(B, device=device), g_best_indices_new]  # B x n\n",
    "\n",
    "                    g_best_position = torch.where(\n",
    "                        update_mask.unsqueeze(-1),\n",
    "                        g_best_position_new,\n",
    "                        g_best_position\n",
    "                    )  # B x n\n",
    "\n",
    "                # Lưu lại fitness tốt nhất cho mỗi lần chạy\n",
    "                best_fitness_per_problem.append(g_best_fitness.cpu().numpy())\n",
    "\n",
    "            # Tính toán các giá trị cần thiết cho từng bài toán\n",
    "            best_fitness_per_problem = np.array(best_fitness_per_problem)  # (pso_iterations x B)\n",
    "            best_fitness = best_fitness_per_problem.min(axis=0)  # Giá trị tốt nhất từng bài toán\n",
    "            worst_fitness = best_fitness_per_problem.max(axis=0)  # Giá trị tệ nhất từng bài toán\n",
    "            avg_fitness = best_fitness_per_problem.mean(axis=0)  # Giá trị trung bình từng bài toán\n",
    "\n",
    "            # Lưu kết quả\n",
    "            for i in range(B):\n",
    "                results.append({\n",
    "                    \"problem_id\": batch_id * B + i,\n",
    "                    \"best_fitness\": best_fitness[i],\n",
    "                    \"worst_fitness\": worst_fitness[i],\n",
    "                    \"avg_fitness\": avg_fitness[i]\n",
    "                })\n",
    "\n",
    "            all_best_fitness.extend(best_fitness)\n",
    "\n",
    "    # Tính giá trị trung bình tốt nhất của tất cả các bài toán\n",
    "    overall_best_avg = np.mean(all_best_fitness)\n",
    "\n",
    "    # In kết quả\n",
    "    for result in results:\n",
    "        print(f\"Problem {result['problem_id']} - Best: {result['best_fitness']:.4f}, \"\n",
    "              f\"Worst: {result['worst_fitness']:.4f}, Avg: {result['avg_fitness']:.4f}\")\n",
    "\n",
    "    print(f\"\\nOverall Average Best Fitness: {overall_best_avg:.4f}\")\n",
    "    return results, overall_best_avg\n",
    "\n",
    "\n",
    "# Example code to run the test_model\n",
    "def run_test(model, test_loader, num_cities, seed=None, load_path=None):\n",
    "    if load_path:\n",
    "        print(f\"Loading model from {load_path}...\")\n",
    "        model.load_state_dict(torch.load(load_path))\n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "    print(\"Running test...\")\n",
    "    results, overall_best_avg = test_model(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        num_cities=num_cities,\n",
    "        pso_iterations=5,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        seed=seed\n",
    "    )\n",
    "    print(\"Test completed.\")\n",
    "    return results, overall_best_avg\n",
    "\n",
    "\n",
    "# Run example test case\n",
    "if __name__ == \"__main__\":\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    # Giả định rằng TSPDataset và mô hình đã được định nghĩa từ trước\n",
    "    test_dataset = \"/kaggle/input/20-test/test\"\n",
    "    test_loader = create_dataloader(test_dataset, num_cities = 20, batch_size = 32, shuffle=True)\n",
    "\n",
    "    # Tạo một mô hình giả định đã được huấn luyện\n",
    "    model = CityGNN(input_dim=2, hidden_dim=128, output_dim=3, num_cities=20)\n",
    "\n",
    "    # Chạy test\n",
    "    results, overall_best_avg = run_test(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        num_cities=20,\n",
    "        seed=625,\n",
    "        load_path=\"psognn.pth\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6415516,
     "sourceId": 10359244,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6423790,
     "sourceId": 10370747,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
